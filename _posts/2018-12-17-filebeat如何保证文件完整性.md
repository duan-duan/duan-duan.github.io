---
title: Filebeat如何保证文件完整性
date: 2018-12-17 23:29:53
categories:
- Filebeat
tags:
- Filebeat
- 日志
---

# Filebeat如何保证在日志文件被切割(或滚动rolling)时依然正确读取文件

因为收集日志是通过文件的inode的，linux中重名名，只是改变了文件名，文件在磁盘的存储位置即inode并未改变。

filebeat中的data下面的registry 可以查看filebeat读取的文件和offset。如
重命名:
mv table_io_1.log table_io_3.log

filebeat的日志中也可以看出来的会有一条。文件名字修改记录
filebeat.prospector.log.files.renamed=1



如果只用当前文件描述符一路监控到天黑的话，那么当logback把日志重命名后，filebeat仍然会监控重命名后的日志，新创建的日志文件就看不到了。实际上，filebeat是通过`close_inactive`和`scan_frequency`两个参数(机制)来应对这种情况的：

- close_inactive 
  该参数指定当被监控的文件多长时间没有变化后就关闭文件句柄(file handle)。官方建议将这个参数设置为一个比文件最大更新间隔大的值。比如文件最长5s更新一次，那就设置成1min。默认值为5min.
- scan_frequency 
  该参数指定Filebeat搜索新文件的频率(时间间隔)。当发现新的文件被创建时， Filebeat会为它再启动一个 harvester 进行监控。默认为10s。

综合以上两个机制，当logback完成日志切割后(即重命名)，此时老的harvester仍然在监控重命名后的日志文件，但是由于该文件不会再更新，因此会在`close_inactive`时间后关闭这个文件的 harvester。当`scan_frequency`时间过后，Filebeat会发现目录中出现了新文件，于是为该文件启动 harvester 进行监控。这样就保证了切割日志时也能不丢不重的传输数据。(不重是通过为每个日志文件保存offset实现的)



第一次安装filebeat的时候，文件的读取是否是把文件全部一次性的收集还是收集新增的呢？

默认是全部收集，不过可以通过参数 tail_files: true 进行调整，以免一次读取了很多不需要的日志。